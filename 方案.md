这个设计思路**是对路的**，而且很符合你现在的主线（**SQL→ 表格 → 共享协作 →AI 注解 → 图表 → 解释文档**）。
关键在于：**别把“每个基础函数”都做成 agent**，而是把它们组合成**任务级（task-level）的 EDA agents**，再用 Strands 做一个“可控的路由 + 工作流编排”。

下面我按“可落地、两个月能做完、还能拿分”的标准，把方案拆成清晰的层次与组件。

---

## 1) 这个想法为什么合理

### Strands 适合你这种“多步骤、强依赖”的任务编排

Strands 的官方文档把“workflow”定义为：把复杂任务拆成多个专长 agent，按明确顺序/依赖协作，保证可靠、可维护、可观察的执行。([Strands Agents][1])
你要做的 EDA（profile→insight→chart→doc→ 保存共享）就是典型“多步骤 + 强依赖”的流程。

### Strands 能直接融入你的 NestJS 技术栈

Strands Agents SDK 同时提供 Python/TypeScript，TypeScript 侧可以 `npm install @strands-agents/sdk` 并用 `Agent` 执行。([Strands Agents][2])
所以你不一定要搞额外 Python 微服务（除非你想）。

### Snowflake AI SQL Functions 本身就是“可组合的原子能力”

比如 AI_COMPLETE 用于生成/解释，AI_CLASSIFY 用于分类。([Snowflake Documentation][3])
把这些当工具（tools），再组合成 EDA 任务是非常自然的。

---

## 2) 但你说的“每个函数就是一个 agent”要稍微改一改粒度

### 现实风险

如果你真的做到：

- `count_nulls()` 一个 agent
- `top_k()` 一个 agent
- `percentile()` 一个 agent
- `ai_complete()` 一个 agent
  会出现：
- agent 数爆炸、调用链变长、调试困难
- LLM 规划/路由变得不稳定
- Demo 很容易抖（比赛最怕抖）

### 更稳的做法（强烈建议）

把“基础函数 + AI SQL”封装成 **任务级 EDA agents**（每个 agent 产出一个可落库的 artifact），而不是把每个原子函数都做成 agent。

> ✅ 原子函数：当 **tool**（工具）
> ✅ 复合函数：当 **agent**（任务执行者）

Strands 也强调 tools 可以用统一的 schema/校验方式封装（Python 的 `@tool` 会抽取元数据、生成 JSON schema 并做验证）。([Strands Agents][4])

---

## 3) 推荐的四层架构（你项目的“正确分层”）

### Layer A：Snowflake 基础 SQL “事实层”

目标：**把表格浓缩成可控上下文**（profile + sample + chart-ready aggregates）

- schema：`INFORMATION_SCHEMA.COLUMNS`
- 统计：`COUNT, COUNT_IF, APPROX_COUNT_DISTINCT, MIN/MAX/AVG, APPROX_PERCENTILE`
- 采样：`QUALIFY ROW_NUMBER() OVER (ORDER BY RANDOM()) <= N`
- 打包：`OBJECT_CONSTRUCT / ARRAY_AGG / TO_JSON`

> 这层输出：`profile_payload`（VARIANT/JSON）

---

### Layer B：AI SQL “解释层”

用 AI SQL 对 profile_payload 进行解释、分类、抽取：

- `AI_COMPLETE`：写洞察、写解释文档、写图表 narrative([Snowflake Documentation][5])
- `AI_CLASSIFY`：识别表类型/风险标签/场景（sales? logs? finance?）([Snowflake Documentation][6])
- `AI_EXTRACT`：抽取列角色（ID/时间/维度/指标）、抽取异常字段列表（MVP 很好用）([Snowflake Documentation][3])

> 这层输出：结构化 JSON（强烈建议用 AI_COMPLETE structured output）

---

### Layer C：复合 EDA Agents（任务级）

每个 agent 产出一个“可共享 artifact”，例如：

1. **TableProfilerAgent**
   输入：table_ref + 可选列/过滤条件
   输出：profile_payload（schema + stats + sample）

2. **InsightAgent**
   输入：profile_payload + user_goal（用户想看什么）
   输出：insights_json（问题、原因、建议、下一步 SQL）

3. **ChartGeneratorAgent**（你说的图生成 agent）
   输入：profile_payload + user_goal
   输出：`[{chart_spec, chart_sql, narrative}]`
   （chart_spec 可用 Vega-Lite/echarts 配置）

4. **AnnotationDocAgent**
   输入：profile_payload + insights + charts
   输出：doc_markdown / doc_json（用于表格注解、交付文档）

5. （可选加分）**ExperienceMemoryAgent**
   输入：insights/doc
   输出：embedding + 相似经验推荐（AI_EMBED / similarity）

---

### Layer D：Strands Workflow Router（编排层）

职责：根据“表信息 + 用户意图”选择工作流，并控制顺序/并行/重试。

Strands workflow 的价值在于：

- 显式控制执行顺序与依赖
- 支持并行/汇合
- 提升可靠性与可维护性([Strands Agents][1])

---

## 4) 你可以落地的 2–3 条 EDA Workflow（两个月内足够）

我建议 **不要做太多**，做 2 条就够 demo 很强。

### Workflow 1：EDA_OVERVIEW（默认）

**适用于任何表**，最稳：

1. ProfilerAgent → profile_payload
2. （并行）InsightAgent + ChartGeneratorAgent
3. AnnotationDocAgent（把两者合并成解释文档）
4. SaveArtifacts（落库 + 共享）

### Workflow 2：EDA_TIME_SERIES（加分）

触发条件（路由逻辑）：

- schema 中存在 DATE/TIMESTAMP 列（或列名像 `date, dt, created_at`）
- 或用户意图包含“趋势/环比/同比”

步骤：

1. ProfilerAgent
2. ChartGeneratorAgent（强制生成时间序列图 + 分组图）
3. InsightAgent（重点解释趋势/异常点）
4. DocAgent

### Workflow 3：EDA_DATA_QUALITY（可选）

触发条件：

- 用户点“质量检查”
- 或 null 率/重复率超过阈值

输出“质量问题 + 建议 SQL 修复动作”。

---

## 5) “路由”怎么做才稳（别让 agent 自己随便想）

你说 Strands 根据表信息 + 用户要求调用 agent——我建议路由分两段：

### ① 先用规则/统计做硬判断（0 成本，稳定）

- 有无时间列？
- 数值列占比？
- 是否存在明显 ID 列（高 distinct、短字符串/数字）
- 行数/列数规模（决定 sample 大小）

### ② 再用 AI_CLASSIFY 做软判断（补充语义）

把 schema + sample 的摘要丢给 AI_CLASSIFY，产出：

- table_type（sales/logs/customer/finance/other）
- recommended_workflow（overview/time_series/quality）

AI_CLASSIFY 就是为“把内容归类到指定标签”设计的。([Snowflake Documentation][6])

> 这样你避免了“LLM 规划 LLM 调用”的黑盒路由，稳定性会显著提升。

---

## 6) 图生成 Agent 怎么设计最像“产品”（而不是玩具）

**ChartGeneratorAgent 的输出建议固定为一个结构化 schema：**

```json
{
  "charts": [
    {
      "title": "Revenue trend by week",
      "chart_type": "line",
      "chart_sql": "SELECT DATE_TRUNC('week', dt) AS x, SUM(revenue) AS y ...",
      "spec": { "vega_lite": { ... } },
      "narrative": ["...bullet1", "...bullet2"]
    }
  ]
}
```

关键点：

- `chart_sql` 让 Snowflake 算事实
- `spec` 让前端画图
- `narrative` 用 AI_COMPLETE 写“解释性注解”，直接进入“可交付文档”

---

## 7) 对你两个月 MVP 的最小 agent 集（我建议就 4 个）

如果你要稳稳交付、Demo 很漂亮：

1. TableProfilerAgent
2. InsightAgent
3. ChartGeneratorAgent
4. AnnotationDocAgent

Strands 只用来编排这 4 个 agent 的 workflow（顺序 + 并行）。

> 这样既符合 Strands 的“多 agent workflow”理念([Strands Agents][1])
> 又不会把系统变成“平台地狱”。

---

## 8) 你这套方案如何在比赛里讲（加分点）

- **创新**：AI SQL 不只是单点调用，而是被封装成可复用的 EDA agents + workflow（方法论工程化）。
- **业务价值**：把咨询团队做 EDA 的经验沉淀成“可共享的表格注解 + 图表解释 + 文档”，减少重复劳动。
- **Demo**：选一张表 → Run AI EDA → 自动生成洞察、图表、解释文档 → 团队成员评论/共享。
- **What worked / didn’t**：比如 token 控制、样本代表性、异常检测误报等。

---

## 给你一句总建议

> **用 Strands 来跑“可控的 EDA 工作流”，每个 agent 产出可共享 artifact；
> 基础 SQL 负责算事实，AI SQL 负责写解释与注解；
> 路由用规则 + AI_CLASSIFY，别做黑盒自由 agent。**

---

如果你愿意，我可以下一步直接把这套设计落到更“可开工”的层面（任选一个）：

1. 这 4 个 agent 的 **输入/输出 JSON schema**（前端展示最需要）
2. EDA_OVERVIEW workflow 的 **SQL 模板 + AI_COMPLETE structured output 模板**
3. NestJS 侧的 **API 路由设计**（`/assets/:id/run-eda`, `/artifacts`, `/comments` 等）
4. 一个 Mermaid 的 workflow 图，直接放 PPT

你想先从哪块开始落地？

[1]: https://strandsagents.com/latest/documentation/docs/user-guide/concepts/multi-agent/workflow/ "Workflow - Strands Agents"
[2]: https://strandsagents.com/latest/documentation/docs/ "Welcome - Strands Agents"
[3]: https://docs.snowflake.com/en/user-guide/snowflake-cortex/aisql?utm_source=chatgpt.com "Snowflake Cortex AI Functions (including LLM functions)"
[4]: https://strandsagents.com/latest/documentation/docs/api-reference/tools/ "Tools - Strands Agents"
[5]: https://docs.snowflake.com/en/sql-reference/functions/ai_complete?utm_source=chatgpt.com "AI_COMPLETE | Snowflake Documentation"
[6]: https://docs.snowflake.com/en/sql-reference/functions/ai_classify?utm_source=chatgpt.com "AI_CLASSIFY | Snowflake Documentation"

这个思路**可以做，而且方向很对**：
把 **“Snowflake 基础 SQL 能力（profiling/聚合/采样/JSON 打包） + AI SQL Functions（AI_COMPLETE/AI_EXTRACT/AI_CLASSIFY…）** 组合成一套 **复合 EDA 能力**，再用 **Strands** 按“表的基本信息 + 用户意图”去编排调用 —— 这本质上是在把你们咨询公司的 EDA 方法论“产品化”。

尤其 Strands 本身就支持 **“Agents as Tools”** 这种模式：用一个 Orchestrator 负责路由，专门的工具型 agent 负责各自任务，强调模块化与可维护性。([Strands Agents][1])

下面我给你一个**工程上可落地、两个月能做出来、同时叙事很比赛友好**的设计方式（重点：**别做成“通用自由智能体平台”，而是做成“任务型 EDA agents + 可控编排”**）。

---

## 1) 先统一概念：你说的“每个函数就是一个 agent”怎么落地最合理

### ✅ 我推荐的分层（最稳）

- **Snowflake 基础函数（SQL Facts Layer）**：负责“算事实”
  - `COUNT/COUNT_IF/APPROX_COUNT_DISTINCT/APPROX_PERCENTILE/DATE_TRUNC/...`
  - `OBJECT_CONSTRUCT/ARRAY_AGG/TO_JSON` 把事实打包成 payload

- **AI SQL Functions（Explain Layer）**：负责“解释事实/生成产物”
  - `AI_EXTRACT`：把 payload 结构化（列角色、关键指标）
  - `AI_CLASSIFY`：给表/列打标签（fact/dim/time-series/log…）
  - `AI_COMPLETE`：写洞察/建议/文档/图表说明

- **EDA “复合能力”（Task Layer）**：把多步组合成可复用任务（这就是你说的复合 EDA 函数）
- **Strands Orchestration（Orchestrator Layer）**：根据用户意图和表特征去调用这些任务

> 关键点：
> **底层不要把每个 AI SQL function 都做成一个 agent**（会碎、会难控、成本会高）。
> 你要做的是 **“每个业务任务一个 agent”**，比如 “EDA Summary Agent / Chart Agent / Doc Agent”。

这和 Strands 的 “Agents as Tools” 思路一致：主控负责路由，专长 agent 负责执行任务。([Strands Agents][1])

---

## 2) 为什么用 Strands 是合适的（但要克制）

### ✅ 好处（你会得到什么）

1. **模块化**：每个任务 agent 一个职责，复用/替换都容易（Strands 也强调 separation of concerns）。([Strands Agents][1])
2. **更像“咨询方法论产品化”**：你不是单次 prompt，而是把 EDA workflow 固化为可执行能力。
3. **可观测性/可调试**：Strands 官方定位是 production-ready、提供 tracing/observability 等能力（适合你做“内部工具”叙事）。([Strands Agents][2])
4. **技术栈匹配**：Strands 有 TypeScript SDK（你是 NestJS/TS 堆栈，能避免再加一个 Python 微服务）。([Strands Agents][2])

### ⚠️ 风险（你必须规避）

- **过度 agent 化**：太多 agent → 结果不可控、Demo 不稳定
- **双层 LLM 成本**：Strands 规划 + Snowflake AI SQL 都会用模型 → token 成本会叠加
- **“平台化陷阱”**：你两个月要交付 MVP，别把时间花在“框架搭建”上

---

## 3) 我建议你做的“EDA Agent 套餐”最小集合（MVP 友好）

下面这些 agent 都是“任务级”，每个都有清晰输入输出，最适合接到你 React 表格工作台里做按钮：

### Agent A：**TableContext Builder（非 LLM，纯 SQL 任务）**

**目的**：为后续 AI 调用准备“浓缩上下文”，控制 token、保护隐私
输出（建议 JSON/VARIANT）：

- 表元数据：列名、类型、注释、主键猜测
- profiling：null_ratio、distinct_ratio、min/max/p95/p99、top values
- 样本行：最多 20–50 行（可脱敏）

> 这一步最好完全 deterministic（不用 LLM），能保证稳定复现。

---

### Agent B：**EDA Summary Agent（AI 解释 + 推荐下一步）**

输入：TableContext + 用户意图（如“帮我找异常/总结趋势/给建议图表”）
内部用：`AI_COMPLETE`（主），配合 `AI_EXTRACT/AI_CLASSIFY`（可选）
输出（强烈建议 structured JSON）：

- key_insights（要点）
- anomalies（异常字段/异常段）
- hypotheses（可能原因）
- recommended_next_sql（下一步建议 SQL）
- recommended_charts（建议图表列表）

---

### Agent C：**Column Annotation Agent（列级解释与注解）**

输入：TableContext + target column(s)
内部用：`AI_EXTRACT`（结构化输出特别适合）
输出：

- column_role（id/dimension/measure/date/text）
- business_meaning（业务含义）
- risk_checks（风险/口径问题）
- suggested_transform（清洗建议）

---

### Agent D：**Chart Generation Agent（图生成 + 解读）**

这是你说的“图生成 agent”，我建议拆成两段（更稳）：

1. **Chart Planner**（AI 规划）
   - 输入：TableContext + 用户要回答的问题
   - 输出：推荐的 chart 类型、x/y 字段、分组字段、所需聚合、对应 SQL 模板

2. **Chart Builder**（SQL 出图数据 + AI 产 spec & narrative）
   - SQL 生成 chart-ready 数据（比如按日/周聚合）
   - AI 生成：
     - 图表 spec（推荐 Vega-Lite / ECharts option JSON）
     - 图表解释文案（bullet + 短段落）

> 这样前端 React 只要接收 “data + spec”，就能稳定渲染并保存为共享资产。

---

### Agent E：**Doc Generator Agent（解释性文档）**

输入：TableContext + EDA Summary + 图表 outputs + 用户注释
内部用：`AI_COMPLETE` 生成 Markdown 文档
输出：

- 文档 markdown
- 引用的表/列/图表列表（便于链接回 workspace）

---

## 4) Strands 编排方式：别做“自由 agent”，做“意图路由 + 固定 workflow”

你说“用 strands 根据表基本信息和用户要求调用 agent”——我建议这样实现：

### Step 1：Intent 分类（轻量、可控）

- **优先规则**：如果用户点了 “生成图表”，那就是 chart
- 否则可用 `AI_CLASSIFY` 对用户请求分类成：
  - `eda_summary`
  - `annotate_columns`
  - `generate_charts`
  - `generate_doc`

### Step 2：Orchestrator 只做路由，不做深度推理

Orchestrator 的 tool 列表只有 4–6 个（上面 Agent B–E）
并且在 system prompt 里写清楚：

- 什么时候调用哪个 tool
- 只允许调用一次/最多两次
- 输出必须是 JSON

这跟 Strands “Agents as Tools” 的最佳实践一致：给主控 agent 明确 tool selection guidance，专长 agent 用 focused prompts。([Strands Agents][1])

### Step 3：用“Workflow/Graph”更稳（可选）

Strands 文档里提供了 multi-agent 的 Graph/Workflow 等模式入口。([Strands Agents][2])
你可以把：

- EDA_BASIC Workflow
- CHART Workflow
- DOC Workflow
  都写成固定节点序列，结果更可复现。

---

## 5) “Snowflake 基础函数 + AI SQL”在你的体系里的最佳配合点

你之前说要配合基本函数，这里就是最关键的 pairing：

### 你用基础 SQL 做：

- Profiling（统计事实）
- Sampling（控制 token）
- Aggregation（图表数据）
- JSON Packaging（标准化输入）

### 你用 AI SQL 做：

- 解释（AI_COMPLETE）
- 结构化提取（AI_EXTRACT）
- 分类/标签（AI_CLASSIFY） -（可选）经验沉淀（AI_EMBED）

Snowflake 自己也在 AISQL 的介绍里强调：把 AI 能力带进 SQL，让用户用熟悉的 SQL 去构建 AI pipeline。([Snowflake][3])
你这个方案正是 “AI pipeline + collaboration workspace” 的组合，非常比赛友好。

---

## 6) 两个月交付建议：用“2+1”策略控风险

### 必做 2 条主线（稳拿 Demo）

1. **SQL → 表格 → EDA Summary（Agent B）→ 保存共享 artifact**
2. **SQL → 表格 → 图表生成（Agent D）→ 保存共享 artifact**

### 选做 1 条加分线（视进度）

- Column Annotation（Agent C）
  或
- Doc Generator（Agent E）

这样你能保证 Demo 完整闭环：
“从表格 → 得到洞察 → 得到图 → 沉淀经验 → 可共享”，不会因为“agent 平台化”做不完。

---

## 7) 我对你方案的最终评价

### ✅ 这是好方向，理由：

- 把 EDA 方法论固化为可复用能力（咨询公司价值）
- Strands 的 “Agents as Tools” 模式跟你设想高度匹配（orchestrator + specialist agents）([Strands Agents][1])
- 你还能用 TypeScript SDK 融入 NestJS，不必新增 Python 服务，降低复杂度([Strands Agents][2])

### ⚠️ 但成功的关键不是“agent 数量”，而是：

- **每个 agent 的输入输出 contract（JSON schema）必须稳定**
- **workflow 必须可控可复现**
- **AI 只吃摘要 + 样本 + 聚合，不吃全表**

---

如果你愿意，我下一步可以直接帮你把这套体系“落到可实现的规格”上：

1. 画一张 **Agent/Tool 架构图**（PPT 可用）
2. 给每个 agent 定义 **输入/输出 JSON schema**（前端展示会非常稳）
3. 给每个 agent 写 **Snowflake SQL 模板**（基础函数 + AI SQL 的组合）

你想先从哪一个开始？

[1]: https://strandsagents.com/latest/documentation/docs/user-guide/concepts/multi-agent/agents-as-tools/ "Agents as Tools - Strands Agents"
[2]: https://strandsagents.com/latest/documentation/docs/ "Welcome - Strands Agents"
[3]: https://www.snowflake.com/en/blog/ai-sql-query-language/?utm_source=chatgpt.com "Cortex AISQL: Reimagining SQL into AI Query Language for ... - Snowflake"
