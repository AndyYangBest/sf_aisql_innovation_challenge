# EDA Workflow æŒä¹…åŒ–ç­–ç•¥

## ğŸ“‹ æ€»ç»“

### å½“å‰çŠ¶æ€
- âœ… Workflow ç»“æœä¿å­˜åœ¨æœ¬åœ°æ–‡ä»¶: `~/.strands/workflows/{workflow_id}.json`
- âŒ æ²¡æœ‰æŒä¹…åŒ–åˆ°æ•°æ®åº“
- âŒ æœåŠ¡å™¨é‡å¯/å®¹å™¨é”€æ¯ä¼šä¸¢å¤±æ•°æ®
- âŒ æ— æ³•æŸ¥è¯¢å†å²è®°å½•

### æ¨èæ–¹æ¡ˆ: åŒå†™ç­–ç•¥ â­

**ä¿ç•™ Strands æœ¬åœ°æ–‡ä»¶ + åŒæ­¥åˆ° PostgreSQL**

---

## ğŸ—„ï¸ æ•°æ®åº“è®¾è®¡

### è¡¨ 1: `eda_workflow_executions` (å¿…é¡»)

å­˜å‚¨ workflow æ‰§è¡Œè®°å½•å’Œç»“æœ

```sql
CREATE TABLE eda_workflow_executions (
    id SERIAL PRIMARY KEY,
    workflow_id VARCHAR(255) UNIQUE NOT NULL,
    workflow_type VARCHAR(50) NOT NULL,  -- EDA_OVERVIEW, EDA_TIME_SERIES, etc.

    -- å…³è”
    table_asset_id INTEGER REFERENCES table_assets(id),
    user_id INTEGER,

    -- çŠ¶æ€
    status VARCHAR(50) DEFAULT 'pending',  -- pending, running, completed, failed
    progress INTEGER DEFAULT 0,  -- 0-100

    -- ä»»åŠ¡ç»Ÿè®¡
    tasks_total INTEGER DEFAULT 0,
    tasks_completed INTEGER DEFAULT 0,
    tasks_failed INTEGER DEFAULT 0,

    -- æ—¶é—´
    started_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE,
    duration_seconds FLOAT,

    -- ç»“æœ (JSON)
    artifacts JSONB,  -- æ‰€æœ‰ä»»åŠ¡ç»“æœ
    summary JSONB,    -- æ‘˜è¦ä¿¡æ¯

    -- ç±»å‹æ£€æµ‹ç»“æœ (é‡è¦! å¯ä»¥ç›´æ¥æŸ¥è¯¢)
    data_structure_type VARCHAR(50),  -- panel, time_series, etc.
    column_type_inferences JSONB,     -- æ‰€æœ‰åˆ—çš„ç±»å‹æ¨æ–­

    -- å…ƒæ•°æ®
    user_intent TEXT,
    error_message TEXT,

    -- å®¡è®¡
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    is_deleted BOOLEAN DEFAULT FALSE
);

CREATE INDEX idx_workflow_executions_table_asset ON eda_workflow_executions(table_asset_id);
CREATE INDEX idx_workflow_executions_status ON eda_workflow_executions(status);
CREATE INDEX idx_workflow_executions_type ON eda_workflow_executions(workflow_type);
CREATE INDEX idx_workflow_executions_structure_type ON eda_workflow_executions(data_structure_type);
```

### è¡¨ 2: `eda_workflow_logs` (å¯é€‰)

å­˜å‚¨é‡è¦çš„ workflow äº‹ä»¶æ—¥å¿—

```sql
CREATE TABLE eda_workflow_logs (
    id SERIAL PRIMARY KEY,
    workflow_execution_id INTEGER REFERENCES eda_workflow_executions(id) ON DELETE CASCADE,

    -- åˆ†ç±»
    log_level VARCHAR(20) NOT NULL,  -- INFO, WARNING, ERROR
    log_type VARCHAR(50) NOT NULL,   -- workflow_started, task_completed, tool_called, etc.

    -- ä¸Šä¸‹æ–‡
    task_id VARCHAR(100),
    tool_name VARCHAR(100),

    -- å†…å®¹
    message TEXT NOT NULL,
    details JSONB,

    -- æ€§èƒ½
    duration_seconds FLOAT,

    -- æ—¶é—´
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_workflow_logs_execution ON eda_workflow_logs(workflow_execution_id);
CREATE INDEX idx_workflow_logs_level ON eda_workflow_logs(log_level);
CREATE INDEX idx_workflow_logs_type ON eda_workflow_logs(log_type);
CREATE INDEX idx_workflow_logs_timestamp ON eda_workflow_logs(timestamp);
```

---

## ğŸ’¾ å®ç°æ–¹æ¡ˆ

### å·²åˆ›å»ºçš„æ–‡ä»¶

1. **`src/app/models/eda_workflow.py`** âœ…
   - `EDAWorkflowExecution` model
   - `EDAWorkflowLog` model

2. **`src/app/services/eda_workflow_persistence.py`** âœ…
   - `EDAWorkflowPersistenceService` class
   - æä¾› CRUD æ“ä½œ

### éœ€è¦é›†æˆçš„åœ°æ–¹

#### 1. åœ¨ `eda_workflows.py` ä¸­é›†æˆ

```python
class EDAOrchestrator:
    def __init__(self, ..., db: AsyncSession | None = None):
        self.db = db  # æ¥æ”¶æ•°æ®åº“ä¼šè¯

    async def run_eda(self, table_asset, user_intent, workflow_type, user_id=None):
        # 1. åˆ›å»ºæ•°æ®åº“è®°å½•
        if self.db:
            persistence = EDAWorkflowPersistenceService(self.db)
            execution = await persistence.create_execution(
                workflow_id=workflow_id,
                workflow_type=workflow_type,
                table_asset_id=table_asset.id,
                user_intent=user_intent,
                user_id=user_id,
                tasks_total=len(tasks),
            )

        try:
            # 2. æ‰§è¡Œ Strands workflow (å†™å…¥æœ¬åœ°æ–‡ä»¶)
            ...

            # 3. è¯»å–æœ¬åœ°æ–‡ä»¶ç»“æœ
            workflow_data = json.load(open(workflow_file))
            artifacts = self._extract_artifacts_from_workflow_data(workflow_data)
            summary = self._generate_summary_from_workflow_data(workflow_data)

            # 4. æ›´æ–°æ•°æ®åº“è®°å½•
            if self.db:
                await persistence.complete_execution(
                    workflow_id=workflow_id,
                    artifacts=artifacts,
                    summary=summary,
                )

        except Exception as e:
            # 5. å¤±è´¥æ—¶æ›´æ–°çŠ¶æ€
            if self.db:
                await persistence.fail_execution(
                    workflow_id=workflow_id,
                    error_message=str(e),
                )
            raise
```

#### 2. åœ¨ API ç«¯ç‚¹ä¸­ä½¿ç”¨

```python
# src/app/api/v1/eda.py
from app.core.db.database import async_get_db

@router.post("/analyze/{table_asset_id}")
async def analyze_table(
    table_asset_id: int,
    user_intent: str = None,
    db: AsyncSession = Depends(async_get_db),
):
    # è·å– table asset
    table_asset = await get_table_asset(db, table_asset_id)

    # åˆ›å»º orchestrator (ä¼ å…¥ db)
    orchestrator = create_eda_orchestrator(
        sf_service,
        ai_sql_service,
        db=db  # â­ ä¼ å…¥æ•°æ®åº“ä¼šè¯
    )

    # è¿è¡Œåˆ†æ
    results = await orchestrator.run_eda(
        table_asset=table_asset,
        user_intent=user_intent,
        user_id=current_user.id,  # ä»è®¤è¯ä¸­è·å–
    )

    return results

@router.get("/history/{table_asset_id}")
async def get_analysis_history(
    table_asset_id: int,
    db: AsyncSession = Depends(async_get_db),
):
    """è·å–æŸä¸ªè¡¨çš„åˆ†æå†å²"""
    persistence = EDAWorkflowPersistenceService(db)
    executions = await persistence.get_executions_for_table(table_asset_id)

    return {
        "table_asset_id": table_asset_id,
        "executions": [
            {
                "id": e.id,
                "workflow_id": e.workflow_id,
                "workflow_type": e.workflow_type,
                "status": e.status,
                "data_structure_type": e.data_structure_type,
                "started_at": e.started_at,
                "completed_at": e.completed_at,
                "duration_seconds": e.duration_seconds,
            }
            for e in executions
        ]
    }
```

---

## ğŸ“Š ä½¿ç”¨åœºæ™¯

### 1. æŸ¥è¯¢åˆ†æå†å²

```python
# è·å–æŸä¸ªè¡¨çš„æ‰€æœ‰åˆ†æè®°å½•
executions = await persistence.get_executions_for_table(table_asset_id=1)

for execution in executions:
    print(f"Workflow: {execution.workflow_type}")
    print(f"Status: {execution.status}")
    print(f"Data Structure: {execution.data_structure_type}")
    print(f"Completed: {execution.completed_at}")
```

### 2. ç»Ÿè®¡åˆ†æ

```sql
-- åˆ†ææˆåŠŸç‡
SELECT
    workflow_type,
    COUNT(*) as total,
    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as success,
    AVG(duration_seconds) as avg_duration
FROM eda_workflow_executions
GROUP BY workflow_type;

-- æœ€å¸¸åˆ†æçš„è¡¨
SELECT
    table_asset_id,
    COUNT(*) as analysis_count,
    MAX(completed_at) as last_analyzed
FROM eda_workflow_executions
WHERE status = 'completed'
GROUP BY table_asset_id
ORDER BY analysis_count DESC
LIMIT 10;

-- æ•°æ®ç»“æ„ç±»å‹åˆ†å¸ƒ
SELECT
    data_structure_type,
    COUNT(*) as count
FROM eda_workflow_executions
WHERE data_structure_type IS NOT NULL
GROUP BY data_structure_type;
```

### 3. é‡ç”¨å†å²ç»“æœ

```python
# æ£€æŸ¥æ˜¯å¦æœ‰æœ€è¿‘çš„åˆ†æç»“æœ
recent_execution = await db.execute(
    select(EDAWorkflowExecution)
    .where(
        EDAWorkflowExecution.table_asset_id == table_asset_id,
        EDAWorkflowExecution.status == "completed",
        EDAWorkflowExecution.completed_at > datetime.now() - timedelta(hours=24)
    )
    .order_by(EDAWorkflowExecution.completed_at.desc())
    .limit(1)
)

if recent_execution:
    # ç›´æ¥è¿”å›ç¼“å­˜çš„ç»“æœ
    return recent_execution.artifacts
else:
    # è¿è¡Œæ–°çš„åˆ†æ
    results = await orchestrator.run_eda(...)
```

---

## ğŸš€ è¿ç§»æ­¥éª¤

### 1. åˆ›å»ºæ•°æ®åº“è¡¨

```bash
# ç”Ÿæˆè¿ç§»æ–‡ä»¶
alembic revision --autogenerate -m "add eda workflow execution tables"

# è¿è¡Œè¿ç§»
alembic upgrade head
```

### 2. æ›´æ–°ä»£ç 

- âœ… Models å·²åˆ›å»º (`eda_workflow.py`)
- âœ… Service å·²åˆ›å»º (`eda_workflow_persistence.py`)
- â³ éœ€è¦ä¿®æ”¹ `eda_workflows.py` é›†æˆæŒä¹…åŒ–
- â³ éœ€è¦åœ¨ API ç«¯ç‚¹ä¸­ä¼ å…¥ `db` å‚æ•°

### 3. æµ‹è¯•

```python
# æµ‹è¯•æŒä¹…åŒ–
async def test_persistence():
    async for db in async_get_db():
        orchestrator = create_eda_orchestrator(
            sf_service,
            ai_sql_service,
            db=db  # ä¼ å…¥æ•°æ®åº“ä¼šè¯
        )

        results = await orchestrator.run_eda(
            table_asset=table_asset,
            user_intent="Test persistence",
        )

        # éªŒè¯æ•°æ®åº“ä¸­æœ‰è®°å½•
        execution = await db.execute(
            select(EDAWorkflowExecution).where(
                EDAWorkflowExecution.workflow_id == results["workflow_id"]
            )
        )
        assert execution is not None
        assert execution.status == "completed"
        assert execution.artifacts is not None
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ•°æ®é‡æ§åˆ¶

**Artifacts å¯èƒ½å¾ˆå¤§** (åŒ…å«å®Œæ•´çš„ JSON ç»“æœ)

ç­–ç•¥:
- âœ… ä½¿ç”¨ JSONB ç±»å‹ (PostgreSQL å‹ç¼©å­˜å‚¨)
- âœ… å®šæœŸæ¸…ç†æ—§è®°å½• (ä¿ç•™æœ€è¿‘ 90 å¤©)
- âš ï¸ è€ƒè™‘åªä¿å­˜æ‘˜è¦ï¼Œå®Œæ•´ç»“æœå­˜ S3

### 2. æ—¥å¿—é‡æ§åˆ¶

**Hook æ—¥å¿—éå¸¸å¤š**

ç­–ç•¥:
- âœ… åªä¿å­˜é‡è¦æ—¥å¿— (workflow_started, task_completed, task_failed)
- âœ… ä¸ä¿å­˜æ¯ä¸ª tool call çš„è¯¦ç»†æ—¥å¿—
- âœ… å®šæœŸæ¸…ç† (ä¿ç•™æœ€è¿‘ 30 å¤©)

### 3. æ€§èƒ½è€ƒè™‘

- âœ… å¼‚æ­¥å†™å…¥æ•°æ®åº“ (ä¸é˜»å¡ workflow)
- âœ… ä½¿ç”¨ç´¢å¼•åŠ é€ŸæŸ¥è¯¢
- âš ï¸ è€ƒè™‘ä½¿ç”¨åå°ä»»åŠ¡å†™å…¥æ—¥å¿—

---

## ğŸ¯ æ¨èå®æ–½é¡ºåº

1. **Phase 1: åŸºç¡€æŒä¹…åŒ–** (å¿…é¡»)
   - âœ… åˆ›å»º `eda_workflow_executions` è¡¨
   - âœ… é›†æˆåˆ° `EDAOrchestrator`
   - âœ… åœ¨ API ä¸­ä¼ å…¥ `db` å‚æ•°

2. **Phase 2: å†å²æŸ¥è¯¢** (æ¨è)
   - æ·»åŠ  API ç«¯ç‚¹æŸ¥è¯¢å†å²
   - æ·»åŠ ç»Ÿè®¡åˆ†æåŠŸèƒ½
   - å®ç°ç»“æœç¼“å­˜

3. **Phase 3: æ—¥å¿—æŒä¹…åŒ–** (å¯é€‰)
   - åˆ›å»º `eda_workflow_logs` è¡¨
   - ä¿®æ”¹ hooks å†™å…¥æ•°æ®åº“
   - å®ç°æ—¥å¿—æŸ¥è¯¢å’Œåˆ†æ

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

- âœ… `src/app/models/eda_workflow.py` - æ•°æ®åº“æ¨¡å‹
- âœ… `src/app/services/eda_workflow_persistence.py` - æŒä¹…åŒ–æœåŠ¡
- â³ `src/app/orchestration/eda_workflows.py` - éœ€è¦é›†æˆ
- â³ `src/app/api/v1/eda.py` - éœ€è¦æ·»åŠ  API ç«¯ç‚¹
- â³ `alembic/versions/xxx_add_eda_workflow_tables.py` - éœ€è¦åˆ›å»ºè¿ç§»

---

## âœ… æ€»ç»“

### åº”è¯¥ä¿å­˜åˆ° PostgreSQL:
1. âœ… **Workflow æ‰§è¡Œè®°å½•** (å¿…é¡») - æŒä¹…åŒ–ã€å¯æŸ¥è¯¢ã€å¯ç»Ÿè®¡
2. âœ… **ç±»å‹æ£€æµ‹ç»“æœ** (å¿…é¡») - æ–¹ä¾¿æŸ¥è¯¢å’Œåˆ†æ
3. âš ï¸ **Hook æ—¥å¿—** (å¯é€‰) - åªä¿å­˜é‡è¦æ—¥å¿—ï¼Œæ§åˆ¶æ•°é‡

### ä¸éœ€è¦ä¿å­˜:
- âŒ æœ¬åœ° Strands æ–‡ä»¶å¯ä»¥ä¿ç•™ (ä½œä¸ºå¤‡ä»½)
- âŒ è¯¦ç»†çš„ tool call æ—¥å¿— (å¤ªå¤šäº†)

### å®æ–½å»ºè®®:
- ä½¿ç”¨**åŒå†™ç­–ç•¥**: Strands æœ¬åœ°æ–‡ä»¶ + PostgreSQL
- å…ˆå®æ–½ Phase 1 (åŸºç¡€æŒä¹…åŒ–)
- æ ¹æ®éœ€æ±‚é€æ­¥æ·»åŠ  Phase 2 å’Œ Phase 3
